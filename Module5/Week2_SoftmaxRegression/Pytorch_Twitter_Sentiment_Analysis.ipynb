{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECrVwhHTSJRQ"
   },
   "source": [
    "## **0. Download dataset**\n",
    "\n",
    "```\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7aN3wiivdUO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\Anaconda3\\envs\\pythonEnv\\Lib\\site-packages\\gdown\\__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1e1uIwcJ1-MviSn9yk_ldPGffDWVp6yK_\n",
      "To: d:\\NgocDai\\AIO24\\AIO2024_AIO-056\\Module5\\Week2_SoftmaxRegression\\twitter_sentiment_analysis_3cls_dataset.zip\n",
      "\n",
      "  0%|          | 0.00/7.97M [00:00<?, ?B/s]\n",
      "  7%|▋         | 524k/7.97M [00:00<00:02, 2.80MB/s]\n",
      " 33%|███▎      | 2.62M/7.97M [00:00<00:00, 9.71MB/s]\n",
      "100%|██████████| 7.97M/7.97M [00:00<00:00, 19.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "# https://drive.google.com/file/d/1e1uIwcJ1-MviSn9yk_ldPGffDWVp6yK_/view?usp=drive_link\n",
    "!gdown --id 1e1uIwcJ1-MviSn9yk_ldPGffDWVp6yK_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jkru2bLe4l01"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('twitter_sentiment_analysis_3cls_dataset.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9govEkfdTJVA"
   },
   "source": [
    "## **1. Import libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAvQLqFPTHr1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuyqHDI8TVf0"
   },
   "source": [
    "## **2. Read dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0uWI9h4TXuN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162975</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162976</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162977</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162978</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162979</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "0       when modi promised “minimum government maximum...      -1.0\n",
       "1       talk all the nonsense and continue all the dra...       0.0\n",
       "2       what did just say vote for modi  welcome bjp t...       1.0\n",
       "3       asking his supporters prefix chowkidar their n...       1.0\n",
       "4       answer who among these the most powerful world...       1.0\n",
       "...                                                   ...       ...\n",
       "162975  why these 456 crores paid neerav modi not reco...      -1.0\n",
       "162976  dear rss terrorist payal gawar what about modi...      -1.0\n",
       "162977  did you cover her interaction forum where she ...       0.0\n",
       "162978  there big project came into india modi dream p...       0.0\n",
       "162979  have you ever listen about like gurukul where ...       1.0\n",
       "\n",
       "[162980 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = 'Twitter_Data.csv'\n",
    "df = pd.read_csv(\n",
    "    dataset_path\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UHefku4Ujgu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162980 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162976 non-null  object \n",
      " 1   category    162973 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DVd0gIgUjx2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>162973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.225436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.781279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            category\n",
       "count  162973.000000\n",
       "mean        0.225436\n",
       "std         0.781279\n",
       "min        -1.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ej3aM_XI-Qm"
   },
   "source": [
    "## **3. Drop missing value**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fWdmBs-JDkg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130448</th>\n",
       "      <td>the foundation stone northeast gas grid inaugu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155642</th>\n",
       "      <td>dear terrorists you can run but you cant hide ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155698</th>\n",
       "      <td>offense the best defence with mission shakti m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155770</th>\n",
       "      <td>have always heard politicians backing out thei...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158693</th>\n",
       "      <td>modi government plans felicitate the faceless ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158694</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159442</th>\n",
       "      <td>chidambaram gives praises modinomics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159443</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160559</th>\n",
       "      <td>the reason why modi contested from seats 2014 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160560</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "148                                                   NaN       0.0\n",
       "130448  the foundation stone northeast gas grid inaugu...       NaN\n",
       "155642  dear terrorists you can run but you cant hide ...       NaN\n",
       "155698  offense the best defence with mission shakti m...       NaN\n",
       "155770  have always heard politicians backing out thei...       NaN\n",
       "158693  modi government plans felicitate the faceless ...       NaN\n",
       "158694                                                NaN      -1.0\n",
       "159442               chidambaram gives praises modinomics       NaN\n",
       "159443                                                NaN       0.0\n",
       "160559  the reason why modi contested from seats 2014 ...       NaN\n",
       "160560                                                NaN       1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_rows = df.isnull().any(axis=1)\n",
    "df[null_rows]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzLyWoryI_0t"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRHyuSBuJBlj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 162969 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162969 non-null  object \n",
      " 1   category    162969 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVHQuLtbAv9M"
   },
   "source": [
    "## **4. Preprocessing data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45GNGGYaAxt2"
   },
   "outputs": [],
   "source": [
    "def text_normalize(text):\n",
    "    text = text.lower()\n",
    "    # Retweet old acronym \"RT\" removal\n",
    "    text = re.sub(r'^rt[\\s]+', '', text)\n",
    "    # Hyperlinks removal\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    # Punctuation removal\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    text = ' '.join(words)\n",
    "    # Stemming\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words = text.split()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    text = ' '.join(words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCT-1Bh7Tjhd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19764\\2442437572.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['clean_text'] = df['clean_text'].apply(lambda x: text_normalize(x))\n"
     ]
    }
   ],
   "source": [
    "df['clean_text'] = df['clean_text'].apply(lambda x: text_normalize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FI5FaYVi-4hh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modi promis minimum govern maximum govern expe...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk nonsens continu drama vote modi</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say vote modi welcom bjp told rahul main campa...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ask support prefix chowkidar name modi great s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer among power world leader today trump pu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  modi promis minimum govern maximum govern expe...      -1.0\n",
       "1               talk nonsens continu drama vote modi       0.0\n",
       "2  say vote modi welcom bjp told rahul main campa...       1.0\n",
       "3  ask support prefix chowkidar name modi great s...       1.0\n",
       "4  answer among power world leader today trump pu...       1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2000)\n",
    "X = vectorizer.fit_transform(df['clean_text']).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqLmhRMGBVJn"
   },
   "source": [
    "## **5. label**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPkv9lPfZOxu"
   },
   "outputs": [],
   "source": [
    "n_classes = df['category'].nunique()\n",
    "n_samples = df['category'].size\n",
    "y = np.array(df['category'].to_numpy() + 1, dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oap8OOdJThGz"
   },
   "source": [
    "## **6. Create train, val, test set**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UppH-uK0UROv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "val_size = 0.2\n",
    "test_size = 0.125\n",
    "random_state = 2\n",
    "is_shuffle = True\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=val_size,\n",
    "    random_state=random_state,\n",
    "    shuffle=is_shuffle\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state,\n",
    "    shuffle=is_shuffle\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrZklXUWUZX_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 114078\n",
      "Number of val samples: 32594\n",
      "Number of test samples: 16297\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training samples: {X_train.shape[0]}')\n",
    "print(f'Number of val samples: {X_val.shape[0]}')\n",
    "print(f'Number of test samples: {X_test.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyd5xoaASjkk"
   },
   "source": [
    "## **7. Define Softmax Regression model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ch2h_amKSp89"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SoftmaxRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "        return probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlaR1y46MYsO"
   },
   "source": [
    "### **7.6. Accuracy function**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "s_MALo1zMbh-"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y_hat, y):\n",
    "    acc = (torch.argmax(y_hat, axis=1) == torch.argmax(y, axis=1)).mean()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjTzJ0HtWSMJ"
   },
   "source": [
    "## **8. Training**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vm95Cm9WfnP"
   },
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "epochs = 50\n",
    "torch.manual_seed(random_state)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_state)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = n_classes\n",
    "\n",
    "model = SoftmaxRegression(\n",
    "    input_dim, output_dim\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), lr=lr\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "4PSuHceiZYNX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19764\\2077205316.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(X_train, dtype=torch.float32)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_19764\\2077205316.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(y_train, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.0975, Accuracy: 37.44%\n",
      "Epoch [2/50], Loss: 1.0972, Accuracy: 38.33%\n",
      "Epoch [3/50], Loss: 1.0970, Accuracy: 39.14%\n",
      "Epoch [4/50], Loss: 1.0967, Accuracy: 39.91%\n",
      "Epoch [5/50], Loss: 1.0964, Accuracy: 40.62%\n",
      "Epoch [6/50], Loss: 1.0962, Accuracy: 41.34%\n",
      "Epoch [7/50], Loss: 1.0959, Accuracy: 42.04%\n",
      "Epoch [8/50], Loss: 1.0956, Accuracy: 42.68%\n",
      "Epoch [9/50], Loss: 1.0954, Accuracy: 43.13%\n",
      "Epoch [10/50], Loss: 1.0951, Accuracy: 43.46%\n",
      "Epoch [11/50], Loss: 1.0948, Accuracy: 43.70%\n",
      "Epoch [12/50], Loss: 1.0946, Accuracy: 43.82%\n",
      "Epoch [13/50], Loss: 1.0943, Accuracy: 43.99%\n",
      "Epoch [14/50], Loss: 1.0941, Accuracy: 44.05%\n",
      "Epoch [15/50], Loss: 1.0938, Accuracy: 44.11%\n",
      "Epoch [16/50], Loss: 1.0936, Accuracy: 44.18%\n",
      "Epoch [17/50], Loss: 1.0933, Accuracy: 44.19%\n",
      "Epoch [18/50], Loss: 1.0931, Accuracy: 44.20%\n",
      "Epoch [19/50], Loss: 1.0929, Accuracy: 44.21%\n",
      "Epoch [20/50], Loss: 1.0926, Accuracy: 44.21%\n",
      "Epoch [21/50], Loss: 1.0924, Accuracy: 44.22%\n",
      "Epoch [22/50], Loss: 1.0921, Accuracy: 44.23%\n",
      "Epoch [23/50], Loss: 1.0919, Accuracy: 44.23%\n",
      "Epoch [24/50], Loss: 1.0917, Accuracy: 44.23%\n",
      "Epoch [25/50], Loss: 1.0915, Accuracy: 44.23%\n",
      "Epoch [26/50], Loss: 1.0912, Accuracy: 44.23%\n",
      "Epoch [27/50], Loss: 1.0910, Accuracy: 44.23%\n",
      "Epoch [28/50], Loss: 1.0908, Accuracy: 44.23%\n",
      "Epoch [29/50], Loss: 1.0905, Accuracy: 44.23%\n",
      "Epoch [30/50], Loss: 1.0903, Accuracy: 44.23%\n",
      "Epoch [31/50], Loss: 1.0901, Accuracy: 44.23%\n",
      "Epoch [32/50], Loss: 1.0899, Accuracy: 44.23%\n",
      "Epoch [33/50], Loss: 1.0897, Accuracy: 44.23%\n",
      "Epoch [34/50], Loss: 1.0895, Accuracy: 44.23%\n",
      "Epoch [35/50], Loss: 1.0892, Accuracy: 44.23%\n",
      "Epoch [36/50], Loss: 1.0890, Accuracy: 44.23%\n",
      "Epoch [37/50], Loss: 1.0888, Accuracy: 44.23%\n",
      "Epoch [38/50], Loss: 1.0886, Accuracy: 44.23%\n",
      "Epoch [39/50], Loss: 1.0884, Accuracy: 44.23%\n",
      "Epoch [40/50], Loss: 1.0882, Accuracy: 44.23%\n",
      "Epoch [41/50], Loss: 1.0880, Accuracy: 44.23%\n",
      "Epoch [42/50], Loss: 1.0878, Accuracy: 44.23%\n",
      "Epoch [43/50], Loss: 1.0876, Accuracy: 44.23%\n",
      "Epoch [44/50], Loss: 1.0874, Accuracy: 44.23%\n",
      "Epoch [45/50], Loss: 1.0872, Accuracy: 44.23%\n",
      "Epoch [46/50], Loss: 1.0870, Accuracy: 44.23%\n",
      "Epoch [47/50], Loss: 1.0868, Accuracy: 44.23%\n",
      "Epoch [48/50], Loss: 1.0866, Accuracy: 44.23%\n",
      "Epoch [49/50], Loss: 1.0864, Accuracy: 44.23%\n",
      "Epoch [50/50], Loss: 1.0862, Accuracy: 44.23%\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, X_train, y_train, epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        # Convert input and output data to tensors if needed\n",
    "        inputs = torch.tensor(X_train, dtype=torch.float32)\n",
    "        \n",
    "        # Ensure labels are in integer class index format\n",
    "        if y_train.ndim > 1:  # If y_train is one-hot encoded\n",
    "            labels = torch.tensor(y_train, dtype=torch.long).argmax(dim=1)\n",
    "        else:\n",
    "            labels = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "        # Reset gradients to zero before backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute model predictions\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate loss based on model predictions and true labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Perform backpropagation to calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the index of the max log-probability\n",
    "        accuracy = (predicted == labels).sum().item() / labels.size(0)\n",
    "        \n",
    "        # Print loss and accuracy every 100 epochs\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Example of using the train function\n",
    "train_model(model, criterion, optimizer, X_train, y_train, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
