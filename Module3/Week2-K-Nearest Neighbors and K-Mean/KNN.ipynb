{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 100\n",
      "Test size    : 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data\n",
    "iris_y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split( iris_X, iris_y, test_size=50)\n",
    "\n",
    "print (\"Training size:\", len(y_train))\n",
    "print (\"Test size    :\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "- $weight$ mặc định ***uniform***, tức coi K neighbors như nhau, ***distance*** cách đánh trọng số phải thoải mãn điều kiện là một điểm càng gần điểm test data thì phải được đánh trọng số càng cao (tin tưởng hơn). Cách đơn giản nhất là lấy nghịch đảo của khoảng cách này.\n",
    "- ở trên, scikit-learn còn cung cấp cho chúng ta một cách để đánh trọng số một cách tùy chọn. Ví dụ, một cách đánh trọng số phổ biến khác trong Machine Learning là: <br>\n",
    "    $w_i = \\exp \\left( \\frac{-||\\mathbf{x} - \\mathbf{x}_i||_2^2}{\\sigma^2} \\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print results for 50 test data points:\n",
      "Predicted labels:  [2 0 2 0 0 2 0 2 2 2 2 2 1 0 1 1 0 1 0 1 0 2 1 0 1 2 2 0 2 0 1 1 2 2 2 1 2\n",
      " 0 0 0 0 1 0 1 1 0 1 1 1 1]\n",
      "Ground truth    :  [2 0 2 0 0 2 0 2 2 2 2 2 1 0 1 1 0 1 0 1 0 2 1 0 1 2 2 0 2 0 1 1 2 2 2 1 2\n",
      " 0 0 0 0 1 0 1 1 0 1 1 1 1]\n",
      "Accuracy of 1NN: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2,  weights = 'distance') #p = 2 tức norm 2\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print (\"Print results for 50 test data points:\")\n",
    "print (\"Predicted labels: \", y_pred[:])\n",
    "print (\"Ground truth    : \", y_test[:])\n",
    "print (\"Accuracy of 1NN: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 10NN (customized weights): 100.00 %\n"
     ]
    }
   ],
   "source": [
    "def myweight(distances):\n",
    "    sigma2 = .5 # we can change this number\n",
    "    return np.exp(-distances**2/sigma2)\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 10, p = 2, weights = myweight)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print (\"Accuracy of 10NN (customized weights): %.2f %%\" %(100*accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
